{"cells":[{"cell_type":"markdown","metadata":{"id":"G5rFvdxUwxxC"},"source":["# Demo: database\n","Create and seperate a TF database with augmented images and files for testing, training and validation."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3510,"status":"ok","timestamp":1642519912685,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"},"user_tz":0},"id":"mcEa4RYsTBT4","outputId":"cbb32592-7b81-48f1-fd12-edd7f79cfe38"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["import os\n","import sys\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# Automatically reload imported programmes\n","%load_ext autoreload\n","%autoreload 2\n","\n","\n","# Directories (ammend as necessary)\n","root_dir = '/content/gdrive/MyDrive/IDSAI/PROOF/filament-segmentation'\n","os.chdir(root_dir)  # Move to root_dir\n","sys.path.insert(0, root_dir)\n","\n","\n","# Database choice\n","batch_size = 10\n","num_patches = 1  # Subsample taining data\n","num_duplicates = 30  # Repeats of subsamples to augment\n","apply_augmentation = True\n","shuffle_on = True\n","\n","\n","# Locate data\n","data_file = 'tomograms2D/all'  # No leading/trailing `/`\n","database_name = 'all-2D-augmented'\n","\n","\n","# Add data to root directory and locate JSON file\n","data_dir = os.path.join(root_dir, 'data/' + data_file)\n","image_path = os.path.join(data_dir, 'png-original')\n","masks_path = os.path.join(data_dir, 'png-masks/semantic/*.png')\n","\n","\n","\n","# New training and validation files\n","train_dir = os.path.join(root_dir, 'data/databases/' + database_name + '/train')\n","valid_dir = os.path.join(root_dir, 'data/databases/' + database_name + '/valid')"]},{"cell_type":"markdown","metadata":{"id":"uByiLbl6x8qg"},"source":["## Create TF database for training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93oYAireWI-K"},"outputs":[],"source":["import tensorflow as tf\n","from loader import augment_data, get_data\n","\n","\n","print('\\nProcessing data...')\n","train_imgs, train_msks, valid_imgs, valid_msks, _, _ = \\\n","    get_data(path_train_imgs=image_path,\n","             path_train_msks=masks_path,\n","             path_valid_imgs='',\n","             path_valid_msks='',\n","             train_frac=0.8,\n","             valid_frac=0.1,\n","             image_size=[256, 256],\n","             num_patches_per_image=num_patches,\n","             num_duplicates_per_image=num_duplicates,\n","             )\n","    \n","train_set, valid_set = augment_data(train_imgs,\n","                                    train_msks,\n","                                    valid_imgs,\n","                                    valid_msks,\n","                                    batch_size,\n","                                    one_hot=False,\n","                                    augment_on=apply_augmentation,\n","                                    shuffle_on=True,\n","                                    )\n","\n","tf.data.experimental.save(train_set, train_dir)\n","tf.data.experimental.save(valid_set, valid_dir)\n","\n","print('Data processed and saved.\\n')\n","print('Training set length: ', len(train_set))\n","print('Validation set length: ', len(valid_set))"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"load-database.ipynb","toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyMVr4ZecChAw61Tkyj2CDys"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}