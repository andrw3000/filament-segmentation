{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"load-database.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNOkU3Xy/l8k41IPpkbh9dn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Demo: database\n","Create and seperate a TF database with augmented images and files for testing, training and validation."],"metadata":{"id":"G5rFvdxUwxxC"}},{"cell_type":"code","metadata":{"id":"mcEa4RYsTBT4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641469594117,"user_tz":0,"elapsed":3429,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}},"outputId":"7cb8709f-5a0c-44ec-91fb-84e47e942316"},"source":["import os\n","import sys\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# Automatically reload imported programmes\n","%load_ext autoreload\n","%autoreload 2\n","\n","# Directories (ammend as necessary)\n","root_dir = '/content/gdrive/MyDrive/IDSAI/PROOF/filament-segmentation'\n","os.chdir(root_dir)  # Move to root_dir\n","sys.path.insert(0, root_dir)\n","\n","# Locate data\n","data_file = 'tomograms2D/tf1'  # No leading/trailing `/`\n","\n","# Add data to root directory and locate JSON file\n","data_dir = os.path.join(root_dir, 'data/' + data_file)\n","image_path = os.path.join(data_dir, 'png-original/*.png')\n","masks_path = os.path.join(data_dir, 'png-masks/semantic')\n","\n","# New training and validation files\n","train_dir = os.path.join(root_dir, 'databases/' + data_file + '/train')\n","valid_dir = os.path.join(root_dir, 'databases/' + data_file + '/valid')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["## Create TF database for training"],"metadata":{"id":"uByiLbl6x8qg"}},{"cell_type":"code","metadata":{"id":"93oYAireWI-K","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b9dd6d98-2e76-43b0-a5f5-e8e81c501ddd"},"source":["import tensorflow as tf\n","from loader import augment_data, get_data\n","batch_size = 10\n","\n","print('\\nProcessing data...')\n","train_imgs, train_msks, valid_imgs, valid_msks, _, _ = \\\n","    get_data(path_train_imgs=image_path,\n","                path_train_msks=masks_path,\n","                path_valid_imgs='',\n","                path_valid_msks='',\n","                train_frac=0.8,\n","                valid_frac=0.1,\n","                image_size=[512, 512],\n","                num_images_per_original=20,\n","                )\n","    \n","train_set, valid_set = augment_data(\n","    train_imgs, train_msks, valid_imgs, valid_msks, batch_size,\n",")\n","\n","tf.data.experimental.save(train_set, train_dir)\n","tf.data.experimental.save(valid_set, valid_dir)\n","\n","print('Data processed and saved.\\n')\n","print('Training set length: ', len(train_set))\n","print('Validation set length: ', len(valid_set))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Processing data...\n"]}]}]}