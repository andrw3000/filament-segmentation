{"cells":[{"cell_type":"markdown","metadata":{"id":"E6oq8m1yjrBr"},"source":["# Training a UNet for Image Segmentation"]},{"cell_type":"markdown","metadata":{"id":"SVtdO3qtHKj8"},"source":["Organise data directories containing training data."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25030,"status":"ok","timestamp":1642635131878,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"},"user_tz":0},"id":"0eE2aYn4HDwa","outputId":"9a411469-1fae-4e18-b9a1-89cc4129e73d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["import os\n","import sys\n","import h5py  # !pip install pyyaml h5py\n","import time\n","import numpy as np\n","from tqdm.notebook import tqdm\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","\n","# Automatically reload imported programmes\n","%load_ext autoreload\n","%autoreload 2\n","\n","\n","# Model/database choice\n","dataset_name = 'all2D'  # Refers to data_file = 'tomograms2D/all'\n","augmentation_choice = 'full'  # Choose from 'zoom'/'full'/'none'\n","loss_name = 'mse'  # Mean Squared Error/Sparse Cat Cross Entropy: 'mse'/'scce'\n","use_existing_weights = True  # If available\n","\n","\n","# Locate data\n","data_file = 'tomograms2D/all'  # No leading/trailing `/`\n","database_name = dataset_name + '-' + augmentation_choice\n","exp_name = 'unet-' + database_name + '-' + loss_name\n","\n","\n","# Directories (ammend as necessary)\n","root_dir = '/content/gdrive/MyDrive/IDSAI/PROOF/filament-segmentation'\n","os.chdir(root_dir)  # Move to root_dir\n","sys.path.insert(0, root_dir)\n","\n","\n","# Add data to root directory and locate JSON file\n","data_dir = os.path.join(root_dir, 'data/' + data_file)\n","image_path = os.path.join(data_dir, 'png-original')\n","masks_path = os.path.join(data_dir, 'png-masks/semantic/*.png')\n","\n","\n","# New training and validation files\n","train_dir = os.path.join(root_dir, 'data/databases/' + database_name + '/train')\n","valid_dir = os.path.join(root_dir, 'data/databases/' + database_name + '/valid')\n","\n","\n","# Checkpoints\n","checkpoint_dir = os.path.join(root_dir, 'checkpoints')\n","if not os.path.exists(checkpoint_dir):\n","    os.makedirs(checkpoint_dir)\n","best_weights_path = os.path.join(checkpoint_dir, exp_name + '.h5')\n","\n","\n","# Figure Outputs\n","fig_dir = os.path.join(root_dir, 'outputs/unet-train-' + database_name)\n","os.makedirs(fig_dir, exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"v8ErMPtHKAPh"},"source":["Choose network parameters."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"G6jeXNsuDUrq","executionInfo":{"status":"ok","timestamp":1642635131879,"user_tz":0,"elapsed":13,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"outputs":[],"source":["lr = 0.0001\n","epoch_freq = 10\n","num_epochs = 1000"]},{"cell_type":"markdown","metadata":{"id":"KfF-BJQpJ2XU"},"source":["Assert GPU/TPU and RAM capability."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Kqp1c0wdt2rF","executionInfo":{"status":"ok","timestamp":1642635131880,"user_tz":0,"elapsed":12,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"outputs":[],"source":["%%script false\n","# GPU info\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","   print(gpu_info)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Btu9gegjuAPw","executionInfo":{"status":"ok","timestamp":1642635131880,"user_tz":0,"elapsed":11,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"outputs":[],"source":["%%script false\n","# TPU initialisation for tensorflow 2.X\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)\n","print(\"All devices: \", tf.config.list_logical_devices('TPU'))"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"RYbH70JJtJiE","executionInfo":{"status":"ok","timestamp":1642635131881,"user_tz":0,"elapsed":12,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"outputs":[],"source":["%%script false\n","## RAM availability\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"markdown","metadata":{"id":"-EMTSZfGGvMk"},"source":["## Load or import data"]},{"cell_type":"markdown","source":["Data choice."],"metadata":{"id":"lrziffVM2Ze_"}},{"cell_type":"code","source":["batch_size = 10\n","shuffle_on = True\n","\n","if augmentation_choice == 'zoom':\n","    num_patches = 20  # Subsample taining data before augmenting\n","    num_duplicates = 1\n","    apply_augmentation = True\n","\n","elif augmentation_choice == 'full':\n","    num_patches = 1\n","    num_duplicates = 30  # Duplicate full image to augment\n","    apply_augmentation = True\n","    \n","elif augmentation_choice == 'none':\n","    num_patches = 1\n","    num_duplicates = 1\n","    apply_augmentation = False  # No augmentation (small dataset)\n","\n","else:\n","    raise ValueError('Please select a pre-defined augmentation choice.')"],"metadata":{"id":"7LoUP8eq2Y1k","executionInfo":{"status":"ok","timestamp":1642635131881,"user_tz":0,"elapsed":11,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Load from file or compute dataset."],"metadata":{"id":"NvyKchS_4XGV"}},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6764,"status":"ok","timestamp":1642635138635,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"},"user_tz":0},"id":"MV7YwZNnD4HR","outputId":"d320a68b-7673-4e5a-f167-fae8a54169af"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Loading data...\n","Data loaded from file.\n","\n","Training set length:  447\n","Validation set length:  56\n","Batch size:  10\n"]}],"source":["print('\\nLoading data...')\n","if not os.path.exists(train_dir) and not os.path.exists(valid_dir):\n","\n","    from loader import augment_data, get_data\n","    train_imgs, train_msks, valid_imgs, valid_msks, _, _ = \\\n","        get_data(path_train_imgs=image_path,\n","                 path_train_msks=masks_path,\n","                 path_valid_imgs='',\n","                 path_valid_msks='',\n","                 train_frac=0.8,\n","                 valid_frac=0.1,\n","                 image_size=[256, 256],\n","                 num_patches_per_image=num_patches,\n","                 num_duplicates_per_image=num_duplicates,\n","                 )\n","        \n","    train_set, valid_set = augment_data(train_imgs,\n","                                        train_msks,\n","                                        valid_imgs,\n","                                        valid_msks,\n","                                        batch_size,\n","                                        one_hot=False,\n","                                        augment_on=apply_augmentation,\n","                                        shuffle_on=True,\n","                                        )\n","\n","    tf.data.experimental.save(train_set, train_dir)\n","    tf.data.experimental.save(valid_set, valid_dir)\n","    print('Data processed, loaded and saved.')\n","else:\n","    train_set = tf.data.experimental.load(train_dir)\n","    valid_set = tf.data.experimental.load(valid_dir)\n","    print('Data loaded from file.')\n","print('\\nTraining set length: ', len(train_set))\n","print('Validation set length: ', len(valid_set))\n","print('Batch size: ', batch_size)"]},{"cell_type":"markdown","source":["## Load model and optimisation strategy"],"metadata":{"id":"eTm0-PvNSXEX"}},{"cell_type":"markdown","source":["Define optimisation strategy."],"metadata":{"id":"3VqzQw86SJy7"}},{"cell_type":"code","source":["# Learning rate\n","lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n","    lr, decay_steps=1000, decay_rate=0.75, staircase=True\n",")\n","\n","# Optimiser\n","optimiser = keras.optimizers.Adam(learning_rate=lr_schedule)"],"metadata":{"id":"k_IRKOQySIlD","executionInfo":{"status":"ok","timestamp":1642635138636,"user_tz":0,"elapsed":5,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["Specify loss function and training metrics."],"metadata":{"id":"QCK39Yy_4uX5"}},{"cell_type":"code","source":["if loss_name == 'mse':\n","    loss_fn = keras.losses.MeanSquaredError()\n","    train_metric = keras.metrics.MeanSquaredError()\n","    val_metric = keras.metrics.MeanSquaredError()\n","    num_classes = 1  # Integer class encoding\n","\n","elif loss_name == 'scce':\n","    loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","    train_metric = keras.metrics.SparseCategoricalAccuracy()\n","    val_metric = keras.metrics.SparseCategoricalAccuracy()\n","    num_classes = 1  # One-hot encoded classes\n","\n","else:\n","    raise ValueError('Please select a pre-defined loss_fn choice.')"],"metadata":{"id":"_-RWXutF4wBr","executionInfo":{"status":"ok","timestamp":1642635138636,"user_tz":0,"elapsed":4,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tbrgiKwwIQKT"},"source":["Instantiate model and load the `best-weights.h5` from previous training sessions."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13930,"status":"ok","timestamp":1642635152562,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"},"user_tz":0},"id":"Mu5o9IU7IHCs","outputId":"1c33287a-9233-410f-c341-d83470aba222"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initialising model randomly.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 128, 128, 32  320         ['input_1[0][0]']                \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 128, 128, 32  128        ['conv2d[0][0]']                 \n"," alization)                     )                                                                 \n","                                                                                                  \n"," activation (Activation)        (None, 128, 128, 32  0           ['batch_normalization[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," activation_1 (Activation)      (None, 128, 128, 32  0           ['activation[0][0]']             \n","                                )                                                                 \n","                                                                                                  \n"," separable_conv2d (SeparableCon  (None, 128, 128, 64  2400       ['activation_1[0][0]']           \n"," v2D)                           )                                                                 \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 128, 128, 64  256        ['separable_conv2d[0][0]']       \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_2 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_1[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," separable_conv2d_1 (SeparableC  (None, 128, 128, 64  4736       ['activation_2[0][0]']           \n"," onv2D)                         )                                                                 \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 128, 128, 64  256        ['separable_conv2d_1[0][0]']     \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," max_pooling2d (MaxPooling2D)   (None, 64, 64, 64)   0           ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 64, 64, 64)   2112        ['activation[0][0]']             \n","                                                                                                  \n"," add (Add)                      (None, 64, 64, 64)   0           ['max_pooling2d[0][0]',          \n","                                                                  'conv2d_1[0][0]']               \n","                                                                                                  \n"," activation_3 (Activation)      (None, 64, 64, 64)   0           ['add[0][0]']                    \n","                                                                                                  \n"," separable_conv2d_2 (SeparableC  (None, 64, 64, 128)  8896       ['activation_3[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 64, 64, 128)  512        ['separable_conv2d_2[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_4 (Activation)      (None, 64, 64, 128)  0           ['batch_normalization_3[0][0]']  \n","                                                                                                  \n"," separable_conv2d_3 (SeparableC  (None, 64, 64, 128)  17664      ['activation_4[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 64, 64, 128)  512        ['separable_conv2d_3[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0          ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 32, 32, 128)  8320        ['add[0][0]']                    \n","                                                                                                  \n"," add_1 (Add)                    (None, 32, 32, 128)  0           ['max_pooling2d_1[0][0]',        \n","                                                                  'conv2d_2[0][0]']               \n","                                                                                                  \n"," activation_5 (Activation)      (None, 32, 32, 128)  0           ['add_1[0][0]']                  \n","                                                                                                  \n"," separable_conv2d_4 (SeparableC  (None, 32, 32, 256)  34176      ['activation_5[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 32, 32, 256)  1024       ['separable_conv2d_4[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_6 (Activation)      (None, 32, 32, 256)  0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," separable_conv2d_5 (SeparableC  (None, 32, 32, 256)  68096      ['activation_6[0][0]']           \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 32, 32, 256)  1024       ['separable_conv2d_5[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0          ['batch_normalization_6[0][0]']  \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 16, 16, 256)  33024       ['add_1[0][0]']                  \n","                                                                                                  \n"," add_2 (Add)                    (None, 16, 16, 256)  0           ['max_pooling2d_2[0][0]',        \n","                                                                  'conv2d_3[0][0]']               \n","                                                                                                  \n"," activation_7 (Activation)      (None, 16, 16, 256)  0           ['add_2[0][0]']                  \n","                                                                                                  \n"," conv2d_transpose (Conv2DTransp  (None, 16, 16, 256)  590080     ['activation_7[0][0]']           \n"," ose)                                                                                             \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_transpose[0][0]']       \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_8 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_7[0][0]']  \n","                                                                                                  \n"," conv2d_transpose_1 (Conv2DTran  (None, 16, 16, 256)  590080     ['activation_8[0][0]']           \n"," spose)                                                                                           \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_transpose_1[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 256)  0          ['add_2[0][0]']                  \n","                                                                                                  \n"," up_sampling2d (UpSampling2D)   (None, 32, 32, 256)  0           ['batch_normalization_8[0][0]']  \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 32, 32, 256)  65792       ['up_sampling2d_1[0][0]']        \n","                                                                                                  \n"," add_3 (Add)                    (None, 32, 32, 256)  0           ['up_sampling2d[0][0]',          \n","                                                                  'conv2d_4[0][0]']               \n","                                                                                                  \n"," activation_9 (Activation)      (None, 32, 32, 256)  0           ['add_3[0][0]']                  \n","                                                                                                  \n"," conv2d_transpose_2 (Conv2DTran  (None, 32, 32, 128)  295040     ['activation_9[0][0]']           \n"," spose)                                                                                           \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_transpose_2[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_10 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_9[0][0]']  \n","                                                                                                  \n"," conv2d_transpose_3 (Conv2DTran  (None, 32, 32, 128)  147584     ['activation_10[0][0]']          \n"," spose)                                                                                           \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 32, 32, 128)  512        ['conv2d_transpose_3[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 256)  0          ['add_3[0][0]']                  \n","                                                                                                  \n"," up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 128)  0          ['batch_normalization_10[0][0]'] \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 64, 64, 128)  32896       ['up_sampling2d_3[0][0]']        \n","                                                                                                  \n"," add_4 (Add)                    (None, 64, 64, 128)  0           ['up_sampling2d_2[0][0]',        \n","                                                                  'conv2d_5[0][0]']               \n","                                                                                                  \n"," activation_11 (Activation)     (None, 64, 64, 128)  0           ['add_4[0][0]']                  \n","                                                                                                  \n"," conv2d_transpose_4 (Conv2DTran  (None, 64, 64, 64)  73792       ['activation_11[0][0]']          \n"," spose)                                                                                           \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 64, 64, 64)  256         ['conv2d_transpose_4[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_12 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_11[0][0]'] \n","                                                                                                  \n"," conv2d_transpose_5 (Conv2DTran  (None, 64, 64, 64)  36928       ['activation_12[0][0]']          \n"," spose)                                                                                           \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 64, 64, 64)  256         ['conv2d_transpose_5[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 12  0          ['add_4[0][0]']                  \n","                                8)                                                                \n","                                                                                                  \n"," up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 64  0          ['batch_normalization_12[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 128, 128, 64  8256        ['up_sampling2d_5[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," add_5 (Add)                    (None, 128, 128, 64  0           ['up_sampling2d_4[0][0]',        \n","                                )                                 'conv2d_6[0][0]']               \n","                                                                                                  \n"," activation_13 (Activation)     (None, 128, 128, 64  0           ['add_5[0][0]']                  \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_6 (Conv2DTran  (None, 128, 128, 32  18464      ['activation_13[0][0]']          \n"," spose)                         )                                                                 \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 128, 128, 32  128        ['conv2d_transpose_6[0][0]']     \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_14 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_13[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_7 (Conv2DTran  (None, 128, 128, 32  9248       ['activation_14[0][0]']          \n"," spose)                         )                                                                 \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 128, 128, 32  128        ['conv2d_transpose_7[0][0]']     \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 64  0          ['add_5[0][0]']                  \n","                                )                                                                 \n","                                                                                                  \n"," up_sampling2d_6 (UpSampling2D)  (None, 256, 256, 32  0          ['batch_normalization_14[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 256, 256, 32  2080        ['up_sampling2d_7[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," add_6 (Add)                    (None, 256, 256, 32  0           ['up_sampling2d_6[0][0]',        \n","                                )                                 'conv2d_7[0][0]']               \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 256, 256, 1)  289         ['add_6[0][0]']                  \n","                                                                                                  \n","==================================================================================================\n","Total params: 2,057,825\n","Trainable params: 2,054,049\n","Non-trainable params: 3,776\n","__________________________________________________________________________________________________\n"]}],"source":["from models import get_unet_model\n","\n","# Instantiate model\n","model = get_unet_model(\n","    image_size=(256, 256), num_colour_channels=1, num_classes=num_classes,\n",")\n","\n","# Call model to build and initialise weights\n","example_image, _ = next(iter(train_set))\n","model(example_image)\n","\n","if os.path.exists(best_weights_path) and use_existing_weights:\n","    model.load_weights(best_weights_path)\n","    print('Model loaded with previous `best weights`.')\n","\n","else:\n","    print('Initialising model randomly.')\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"GGhe1-BUITMu"},"source":["## Training Routine"]},{"cell_type":"markdown","source":["Train/test steps."],"metadata":{"id":"7nlkrOqxD1JM"}},{"cell_type":"code","source":["@tf.function\n","def train_step(x, y, metric, loss_fn, opt):\n","    with tf.GradientTape() as tape:\n","        y_pred = model(x, training=True)\n","        loss = loss_fn(y, y_pred)\n","    grads = tape.gradient(loss, model.trainable_weights)\n","    opt.apply_gradients(zip(grads, model.trainable_weights))\n","    metric.update_state(y, y_pred)  # Update training metric\n","    return loss\n","\n","@tf.function\n","def test_step(x, y, loss_fn, metric=None):\n","    y_pred = model(x, training=False)  # Run prediction\n","    loss = loss_fn(y, y_pred)  # Compute loss\n","    if metric is not None:\n","        metric.update_state(y, y_pred)  # Update val metrics\n","    return y_pred, loss"],"metadata":{"id":"WdX_cq4p6n8h","executionInfo":{"status":"ok","timestamp":1642635152562,"user_tz":0,"elapsed":4,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VWljORP_4C_s"},"source":["Iterate training session."]},{"cell_type":"code","source":["# Iterate training session\n","train_losses = []\n","val_losses = []\n","best_epoch = 0\n","\n","for epoch in range(num_epochs):\n","    epoch += 1\n","    print(\"\\nStart of epoch %d\" % (epoch,))\n","    start_time = time.time()\n","\n","    if epoch == 1:\n","        print('Saving model weights at epoch {:d}.'.format(epoch))\n","        model.save_weights(best_weights_path, save_format='h5')\n","\n","    # Iterate over the batches of the dataset\n","    for step, (x_train, y_train) in enumerate(train_set):\n","\n","        # Take training step, optimising model and computing loss\n","        loss = train_step(x_train, y_train, train_metric, loss_fn, optimiser)\n","        train_losses.extend(np.array(loss).flatten())  # Store accumulation\n","\n","        last_train_data = (x_train, y_train)  # Save last value for plotting\n","\n","        # Log every 100 batches\n","        if step % 100 == 0:\n","            print(\"Training loss per batch at step {:03d}: {:.4f}\"\n","                  .format(step, float(loss))\n","            )\n","            # print(\"Seen so far: {:d} samples\".format((step + 1) * batch_size))\n","\n","\n","    # Display metrics at the end of each epoch\n","    train_losses.append(train_metric.result())\n","    train_metric.reset_states()\n","    print(\"Training loss over epoch {:d}: {:.4f}\"\n","          .format(epoch, float(train_losses[-1]))\n","    )\n","\n","\n","    # Validate and checkpoint every `epoch_freq` epochs\n","    if epoch % epoch_freq == 0:\n","\n","        for x_val, y_val in valid_set:\n","            ypred_val, loss_val = test_step(x_val, y_val, loss_fn, val_metric)\n","\n","        val_losses.append(val_metric.result())\n","        val_metric.reset_states()\n","        print(\"Validation loss: {:.4f}\".format(float(val_losses[-1]),))\n","        print(\"Time taken: {:.2f}s\".format(time.time() - start_time))\n","\n","        if epoch > 0 and all(val_losses[-1] <= loss for loss in val_losses):\n","            best_epoch = epoch\n","            print('\\nValidation loss decrease from {:.3f} to {:.3f} '\n","                  'over epochs {:d} to {:d}.'.format(val_losses[-2],\n","                                                     val_losses[-1],\n","                                                     epoch - epoch_freq,\n","                                                     epoch,\n","                                                     )\n","            )\n","\n","            print('Saving initial model weights at epoch {:d}.'.format(epoch))\n","            model.save_weights(best_weights_path, save_format='h5')\n","\n","        else:\n","            print(\n","                '\\nNo validation loss improvement at epoch {:d}.'.format(epoch)\n","            )\n","\n","        # Training predicition for printing\n","        x_train, y_train = last_train_data\n","        ypred_train, loss_train = test_step(x_train, y_train, loss_fn)\n","\n","        # Graphical Output\n","        print('\\n')\n","        print('Training Results.')\n","        print('Range of mask energies: {min:.3f} to {max:.3f}'\n","            .format(min=np.min(ypred_train[0, :, :, 0]),\n","                    max=np.max(ypred_train[0, :, :, 0]),\n","                    )\n","            )\n","        fig, ax = plt.subplots(1, 3, constrained_layout=True)\n","        ax[0].imshow(x_train[0, :, :, 0])\n","        ax[0].set_title('Input')\n","        ax[1].imshow(y_train[0, :, :, 0])\n","        ax[1].set_title('Mask')\n","        ax[2].imshow(ypred_train[0, :, :, 0])\n","        ax[2].set_title('Prediction')\n","        plt.show()\n","        fig.savefig(os.path.join(fig_dir, 'train_epoch{:04d}'.format(epoch)))\n","\n","        print('\\n')\n","        print('Validation Results.')\n","        print('Range of mask energies: {min:.3f} to {max:.3f}'\n","            .format(min=np.min(ypred_val[0, :, :, 0]),\n","                    max=np.max(ypred_val[0, :, :, 0]),\n","                    )\n","            )\n","        fig, ax = plt.subplots(1, 3, constrained_layout=True)\n","        ax[0].imshow(x_val[0, :, :, 0])\n","        ax[0].set_title('Input')\n","        ax[1].imshow(y_val[0, :, :, 0])\n","        ax[1].set_title('Mask')\n","        ax[2].imshow(ypred_val[0, :, :, 0])\n","        ax[2].set_title('Prediction')\n","        plt.show()\n","        fig.savefig(os.path.join(fig_dir, 'valid_epoch{:04d}'.format(epoch)))\n","        print('\\n')"],"metadata":{"id":"fs80WAo3SH2e","colab":{"base_uri":"https://localhost:8080/"},"outputId":"513609e6-3e40-4382-ae02-0fab66aea603"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Start of epoch 1\n","Saving model weights at epoch 1.\n","Training loss per batch at step 000: 0.4107\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eQsGTswbDV5a"},"outputs":[],"source":["# Generate loss plot\n","fig, ax = plt.subplots(1, 1)\n","\n","xt = np.linspace(0, num_epochs - 1, num_epochs)\n","xv = np.linspace(0, num_epochs - epoch_freq, int(num_epochs / epoch_freq))\n","\n","ax.plot(xt, train_losses, color='g', label='Training loss')\n","ax.plot(xv, val_losses, color='r', label='Validation loss')\n","\n","\n","# Best epoch\n","xb, yb = best_epoch, vlosses[int(best_epoch / epoch_freq)]\n","ax.plot(xb, yb,'bo')\n","ax.annotate('{}'.format(best_epoch),\n","            (xb, yb),\n","            textcoords=\"offset points\", # how to position the text\n","            xytext=(0,20), # distance from text to points (x,y)\n","            ha='center')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","ax.legend()\n","plt.show()\n","fig.savefig(os.path.join(fig_dir, 'loss-plot.png'))"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"train-unet.ipynb","provenance":[{"file_id":"1WzsT1DOkzkQN5wroewQjngPuh8XsAtvE","timestamp":1632321587364}],"toc_visible":true,"authorship_tag":"ABX9TyP5FYv0Djq6eVdWgV5TvBvj"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}