{"cells":[{"cell_type":"markdown","metadata":{"id":"E6oq8m1yjrBr"},"source":["# Training a U-Net for Image Segmentation"]},{"cell_type":"markdown","metadata":{"id":"SVtdO3qtHKj8"},"source":["Organise data directories containing training data."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4599,"status":"ok","timestamp":1642521829641,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"},"user_tz":0},"id":"0eE2aYn4HDwa","outputId":"0e70fa96-c136-4aa2-ad25-ff556fae5658"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["import os\n","import sys\n","import h5py  # !pip install pyyaml h5py\n","import numpy as np\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","\n","# Automatically reload imported programmes\n","%load_ext autoreload\n","%autoreload 2\n","\n","\n","# Database choice\n","batch_size = 10\n","num_patches = 1  # Subsample taining data\n","num_duplicates = 30  # Repeats of subsamples to augment\n","apply_augmentation = True\n","shuffle_on = True\n","\n","\n","# Locate data\n","data_file = 'tomograms2D/all'  # No leading/trailing `/`\n","database_name = 'all-2D-augment30'\n","exp_name = 'unet-' + database_name\n","\n","\n","# Directories (ammend as necessary)\n","root_dir = '/content/gdrive/MyDrive/IDSAI/PROOF/filament-segmentation'\n","os.chdir(root_dir)  # Move to root_dir\n","sys.path.insert(0, root_dir)\n","\n","\n","# Add data to root directory and locate JSON file\n","data_dir = os.path.join(root_dir, 'data/' + data_file)\n","image_path = os.path.join(data_dir, 'png-original')\n","masks_path = os.path.join(data_dir, 'png-masks/semantic/*.png')\n","\n","\n","# New training and validation files\n","train_dir = os.path.join(root_dir, 'data/databases/' + database_name + '/train')\n","valid_dir = os.path.join(root_dir, 'data/databases/' + database_name + '/valid')\n","\n","\n","# Checkpoints\n","checkpoint_dir = os.path.join(root_dir, 'checkpoints/' + exp_name)\n","if not os.path.exists(checkpoint_dir):\n","    os.makedirs(checkpoint_dir)\n","checkpoint_path = os.path.join(checkpoint_dir, 'cp-{epoch:04d}.h5')\n","best_weights_path = os.path.join(checkpoint_dir, 'unet-best-weights')\n","\n","\n","# Figure Outputs\n","fig_dir = os.path.join(root_dir, 'outputs/unet-train-' + database_name)\n","os.makedirs(fig_dir, exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"KfF-BJQpJ2XU"},"source":["Assert GPU/TPU and RAM capability."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Kqp1c0wdt2rF","executionInfo":{"status":"ok","timestamp":1642521829642,"user_tz":0,"elapsed":7,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"outputs":[],"source":["%%script false\n","# GPU info\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","   print(gpu_info)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Btu9gegjuAPw","executionInfo":{"status":"ok","timestamp":1642521829642,"user_tz":0,"elapsed":6,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"outputs":[],"source":["%%script false\n","# TPU initialisation for tensorflow 2.X\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)\n","print(\"All devices: \", tf.config.list_logical_devices('TPU'))"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"RYbH70JJtJiE","executionInfo":{"status":"ok","timestamp":1642521829643,"user_tz":0,"elapsed":6,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"outputs":[],"source":["%%script false\n","## RAM availability\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"markdown","metadata":{"id":"-EMTSZfGGvMk"},"source":["## Load data"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"elapsed":720326,"status":"error","timestamp":1642522549964,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"},"user_tz":0},"id":"MV7YwZNnD4HR","outputId":"32fe4421-d3bf-4c78-bb43-e465600a7cbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Loading data...\n"]},{"output_type":"stream","name":"stderr","text":[" 91%|█████████▏| 170/186 [11:53<01:07,  4.20s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-fda3b925841a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                  \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                  \u001b[0mnum_patches_per_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_patches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                  \u001b[0mnum_duplicates_per_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_duplicates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                  )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/IDSAI/PROOF/filament-segmentation/loader/data_loader.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(path_train_imgs, path_train_msks, path_valid_imgs, path_valid_msks, train_frac, valid_frac, image_size, num_patches_per_image, num_duplicates_per_image)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mmsk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsk_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mmsk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mmsk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmsk\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#print('msk.shape: ', msk.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         image = ndi.gaussian_filter(image, anti_aliasing_sigma,\n\u001b[0;32m--> 148\u001b[0;31m                                     cval=cval, mode=ndi_mode)\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;31m# 2-dimensional interpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mgaussian_filter\u001b[0;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             gaussian_filter1d(input, sigma, axis, order, output,\n\u001b[0;32m--> 299\u001b[0;31m                               mode, cval, truncate)\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mgaussian_filter1d\u001b[0;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;31m# Since we are calling correlate, not convolve, revert the kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gaussian_kernel1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrelate1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mcorrelate1d\u001b[0;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     _nd_image.correlate1d(input, weights, axis, output, mode, cval,\n\u001b[0;32m---> 95\u001b[0;31m                           origin)\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["print('\\nLoading data...')\n","if not os.path.exists(train_dir) and not os.path.exists(valid_dir):\n","\n","    from loader import augment_data, get_data\n","    train_imgs, train_msks, valid_imgs, valid_msks, _, _ = \\\n","        get_data(path_train_imgs=image_path,\n","                 path_train_msks=masks_path,\n","                 path_valid_imgs='',\n","                 path_valid_msks='',\n","                 train_frac=0.8,\n","                 valid_frac=0.1,\n","                 image_size=[256, 256],\n","                 num_patches_per_image=num_patches,\n","                 num_duplicates_per_image=num_duplicates,\n","                 )\n","        \n","    train_set, valid_set = augment_data(train_imgs,\n","                                        train_msks,\n","                                        valid_imgs,\n","                                        valid_msks,\n","                                        batch_size,\n","                                        one_hot=False,\n","                                        augment_on=apply_augmentation,\n","                                        shuffle_on=True,\n","                                        )\n","\n","    tf.data.experimental.save(train_set, train_dir)\n","    tf.data.experimental.save(valid_set, valid_dir)\n","    print('Data processed, loaded and saved.')\n","\n","else:\n","\n","    train_set = tf.data.experimental.load(train_dir)\n","    valid_set = tf.data.experimental.load(valid_dir)\n","    print('Data loaded from file.')\n","    \n","print('Training set length: ', len(train_set))\n","print('Validation set length: ', len(valid_set))"]},{"cell_type":"markdown","source":["## Load model"],"metadata":{"id":"wPHmBdno9RGB"}},{"cell_type":"code","source":["from models import get_unet_model\n","\n","# Instantiate model\n","model = get_unet_model((256, 256),\n","                       num_classes=2,\n","                       num_colour_channels=1,\n","                       )\n","\n","model.summary()"],"metadata":{"id":"zW5ZLboY9T6A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GGhe1-BUITMu"},"source":["## Iterate training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MYkpS8zj328L","executionInfo":{"status":"aborted","timestamp":1642522549958,"user_tz":0,"elapsed":13,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"outputs":[],"source":["unet_lr = 0.0001\n","num_epochs = 500\n","batch_size = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mu5o9IU7IHCs","executionInfo":{"status":"aborted","timestamp":1642522549961,"user_tz":0,"elapsed":15,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"outputs":[],"source":["\n","# Optimiser\n","lr = keras.optimizers.schedules.ExponentialDecay(\n","            unet_lr, decay_steps=1000, decay_rate=0.75, staircase=True\n","        )\n","opt = keras.optimizers.RMSprop(learning_rate=lr)\n","\n","# Compile model\n","model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['mean_squared_error', 'mean_absolute_error'],\n","              )\n","\n","# Checkpointing\n","cps = [keras.callbacks.ModelCheckpoint(best_weights_path, save_best_only=True)]\n","\n","# Surpress `CustomMaskWarning`, see: stackoverflow.com/questions/68384466\n","import logging, os\n","logging.disable(logging.WARNING)\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","\n","def int_valued_masks(image, mask):\n","    return image, tf.cast(mask, tf.int16)\n","\n","# Train the model, validating at the end of each epoch.\n","history = model.fit(train_set.map(int_valued_masks),\n","                    epochs=num_epochs,\n","                    validation_data=valid_set.map(int_valued_masks),\n","                    callbacks=cps,\n","                    )\n"]},{"cell_type":"markdown","metadata":{"id":"3rw4EpmB5dbM"},"source":["Analysis of training sucess."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vib9IvVG5rj6","executionInfo":{"status":"aborted","timestamp":1642522549962,"user_tz":0,"elapsed":15,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"outputs":[],"source":["# Plot history: Model loss\n","plt.plot(\n","    history.history['loss'], label='Model loss (training data)'\n",")\n","\n","plt.plot(\n","    history.history['val_loss'], label='Model loss (validation data)'\n",")\n","\n","plt.title('Model loss for U-Net training.')\n","plt.ylabel('Model loss value')\n","plt.xlabel('No. epoch')\n","plt.legend(loc=\"upper left\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XWAbaA8tMWLA","executionInfo":{"status":"aborted","timestamp":1642522549963,"user_tz":0,"elapsed":16,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"outputs":[],"source":["# Plot history: MSE\n","plt.plot(\n","    history.history['mean_squared_error'], label='MSE (training data)'\n","\n",")\n","\n","plt.plot(\n","    history.history['val_mean_squared_error'], label='MSE (validation data)'\n",")\n","\n","plt.title('MSE for U-Net training.')\n","plt.ylabel('MSE value')\n","plt.xlabel('No. epoch')\n","plt.legend(loc=\"upper left\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gXtqXmuFChA-","executionInfo":{"status":"aborted","timestamp":1642522549963,"user_tz":0,"elapsed":16,"user":{"displayName":"Andrew Corbett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfWvSpJcF8ufZCpMOCz9qkF5qYKUu3WQYoyFxl=s64","userId":"01044198545578387343"}}},"outputs":[],"source":["# Plot history: MAE\n","plt.plot(\n","    history.history['mean_absolute_error'], label='MAE (training data)'\n","\n",")\n","\n","plt.plot(\n","    history.history['val_mean_absolute_error'], label='MAE (validation data)'\n",")\n","\n","plt.title('MAE for U-Net training.')\n","plt.ylabel('MAE value')\n","plt.xlabel('No. epoch')\n","plt.legend(loc=\"upper left\")\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"train-unet.ipynb","provenance":[{"file_id":"1WzsT1DOkzkQN5wroewQjngPuh8XsAtvE","timestamp":1632321587364}],"toc_visible":true,"authorship_tag":"ABX9TyO86Y8XTDNU/NMinw2OBoCV"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}