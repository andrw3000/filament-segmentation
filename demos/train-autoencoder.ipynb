{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train-autoencoder.ipynb","provenance":[{"file_id":"1WzsT1DOkzkQN5wroewQjngPuh8XsAtvE","timestamp":1632321587364}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOU0aWp8Sx5Jr9aLJLLLCK+"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"E6oq8m1yjrBr"},"source":["# Training an Autoencoder for Image Segmentation"]},{"cell_type":"markdown","metadata":{"id":"SVtdO3qtHKj8"},"source":["Organise data directories containing training data."]},{"cell_type":"code","source":["import os\n","import sys\n","import h5py  # !pip install pyyaml h5py\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# Automatically reload imported programmes\n","%load_ext autoreload\n","%autoreload 2\n","\n","# Locate data\n","data_file = 'tomograms2D/tf1'  # No leading/trailing `/`\n","\n","# Directories (ammend as necessary)\n","root_dir = '/content/gdrive/MyDrive/IDSAI/PROOF/filament-segmentation'\n","os.chdir(root_dir)  # Move to root_dir\n","sys.path.insert(0, root_dir)\n","\n","# Add data to root directory and locate JSON file\n","data_dir = os.path.join(root_dir, 'data/' + data_file)\n","image_path = os.path.join(data_dir, 'png-original/*.png')\n","masks_path = os.path.join(data_dir, 'png-masks/semantic')\n","\n","# New training and validation files\n","train_dir = os.path.join(root_dir, 'databases/' + data_file + '/train')\n","valid_dir = os.path.join(root_dir, 'databases/' + data_file + '/valid')\n","\n","# Checkpoints\n","checkpoint_dir = os.path.join(root_dir, 'checkpoints')\n","if not os.path.exists(checkpoint_dir):\n","    os.makedirs(checkpoint_dir)\n","ckpt_path = os.path.join(checkpoint_dir, 'cp-{epoch:04d}.h5')"],"metadata":{"id":"0eE2aYn4HDwa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Choose network parameters."],"metadata":{"id":"v8ErMPtHKAPh"}},{"cell_type":"code","metadata":{"id":"G6jeXNsuDUrq"},"source":["lr = 0.0001\n","batch_size = 10\n","num_epochs = 1000\n","num_internal_layers = 3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Assert GPU and RAM capability."],"metadata":{"id":"KfF-BJQpJ2XU"}},{"cell_type":"code","metadata":{"id":"2097xLvReicq"},"source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","    raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RYbH70JJtJiE"},"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-EMTSZfGGvMk"},"source":["## Data Loading"]},{"cell_type":"code","metadata":{"id":"MV7YwZNnD4HR"},"source":["from loader import augment_data, get_data\n","\n","print('\\nLoading data...')\n","if not os.path.exists(train_dir) and not os.path.exists(valid_dir):\n","    train_imgs, train_msks, valid_imgs, valid_msks, _, _ = \\\n","        get_data(path_train_imgs=image_path,\n","                 path_train_msks=masks_path,\n","                 path_valid_imgs='',\n","                 path_valid_msks='',\n","                 train_frac=0.8,\n","                 valid_frac=0.1,\n","                 image_size=[256, 256],\n","                 num_images_per_original=20,\n","                 )\n","    train_set, valid_set = augment_data(\n","        train_imgs, train_msks, valid_imgs, valid_msks, batch_size,\n","    )\n","\n","    \n","\n","    tf.data.experimental.save(train_set, train_dir)\n","    tf.data.experimental.save(valid_set, valid_dir)\n","    print('Data processed, loaded and saved.')\n","else:\n","    train_set = tf.data.experimental.load(train_dir)\n","    valid_set = tf.data.experimental.load(valid_dir)\n","    print('Data loaded from file.')\n","print('Training set length: ', len(train_set))\n","print('Validation set length: ', len(valid_set))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tbrgiKwwIQKT"},"source":["## Model instantiation"]},{"cell_type":"code","metadata":{"id":"mwXsuRaJBej3"},"source":["class Autoencoder(keras.Model):\n","    \"\"\"Defines the encoding-decoding paradigm.\"\"\"\n","    \n","    def __init__(self, autoencoder_lr: float=0.001):\n","        super(Autoencoder, self).__init__()\n","        self.encoder_tup = (self.encoding_conv(1, 256, 1),\n","                            keras.layers.BatchNormalization(),\n","                            self.encoding_conv(256, 128, 2),\n","                            keras.layers.BatchNormalization(),\n","                            self.encoding_conv(128, 64, 2),\n","                            keras.layers.BatchNormalization(),\n","                            self.encoding_conv(64, 32, 2),\n","                            keras.layers.BatchNormalization(),\n","                            self.encoding_conv(32, 8, 2),\n","                            keras.layers.BatchNormalization(),\n","                            )\n","        self.decoder_tup = (self.decoding_conv(8, 8, 2),\n","                            keras.layers.BatchNormalization(),\n","                            self.decoding_conv(8, 16, 2),\n","                            keras.layers.BatchNormalization(),\n","                            self.decoding_conv(16, 32, 2),\n","                            keras.layers.BatchNormalization(),\n","                            self.decoding_conv(32, 64, 2),\n","                            keras.layers.BatchNormalization(),\n","                            self.decoding_conv(64, 128, 2),\n","                            keras.layers.BatchNormalization(),\n","                            self.decoding_conv(128, 256, 2),\n","                            keras.layers.BatchNormalization(),\n","                            self.decoding_conv(256, 1, 1, activation='sigmoid'),\n","                            keras.layers.BatchNormalization(),\n","                            )\n","\n","        self.lr = keras.optimizers.schedules.ExponentialDecay(\n","            autoencoder_lr, decay_steps=1000, decay_rate=0.75, staircase=True\n","        )\n","        self.optimiser = keras.optimizers.Adam(learning_rate=self.lr)\n","\n","    def encoding_conv(self, in_feats, out_feats, stride):\n","        \"\"\"Define bespoke encoding convolution.\"\"\"\n","        return keras.layers.Conv2D(filters=out_feats,\n","                                  kernel_size=(5, 5),\n","                                  input_shape=(None, None, in_feats),\n","                                  strides=(stride, stride),\n","                                  padding='same',\n","                                  data_format='channels_last',\n","                                  activation='relu',\n","                                  )\n","\n","    def decoding_conv(self, in_feats, out_feats, stride, activation='relu'):\n","        \"\"\"Define bespoke decoding convolution.\"\"\"\n","        return keras.layers.Conv2DTranspose(filters=out_feats,\n","                                            kernel_size=(5, 5),\n","                                            input_shape=(None, None, in_feats),\n","                                            strides=(stride, stride),\n","                                            padding='same',\n","                                            data_format='channels_last',\n","                                            activation=activation,\n","                                            )\n","\n","    def call_encoder(self, input, training=False):\n","        state = input\n","        for i in range(len(self.encoder_tup)):\n","            #if i % 2 == 0: print('in '+str(i)+' enc_state: ', state.shape)\n","            state = self.encoder_tup[i](state, training=training)\n","            #if i % 2 == 0: print('out '+str(i)+' enc_state: ', state.shape)\n","        return state\n","\n","    def call_decoder(self, input, training=False):\n","        state = input\n","        for i in range(len(self.decoder_tup)):\n","            #if i % 2 == 0: print('in '+str(i)+' dec_state: ', state.shape)\n","            state = self.decoder_tup[i](state, training=training)\n","            #if i % 2 == 0: print('out '+str(i)+' dec_state: ', state.shape)\n","        return state\n","\n","\n","    def call_both(self, input, training=False):\n","        encoded = self.call_encoder(input, training=training)\n","        decoded = self.call_decoder(encoded, training=training)\n","        return decoded\n","\n","    def optimise_autoencoder(self, x, y, loss_func):\n","        with tf.GradientTape() as g:\n","            enc = self.call_encoder(x, training=True)\n","            x_predict = self.call_decoder(enc, training=True)\n","            loss = tf.math.reduce_mean(loss_func(y, x_predict))\n","        self.optimiser.minimize(\n","            loss, [layer.trainable_weights for layer in\n","                   self.encoder_tup + self.decoder_tup], tape=g\n","                   )\n","        return loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mu5o9IU7IHCs"},"source":["# Instantiate model\n","model = Autoencoder(autoencoder_lr=lr)\n","\n","@tf.function\n","def train_step(data):\n","    images, masks = data\n","    return model.optimise_autoencoder(images, masks, keras.losses.MSE)\n","\n","@tf.function\n","def test_step(data):\n","    images, masks = data\n","    evals = model.call_decoder(model.call_encoder(images))\n","    loss = tf.math.reduce_mean(keras.losses.MSE(evals, masks), axis = 1)\n","    loss = tf.math.reduce_mean(loss, axis = 1)\n","    print ('evals.shape: ', evals.shape)\n","    print ('images.shape: ', images.shape)\n","    print ('loss: ', loss)\n","    return evals, loss, images, masks\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4QmmNqa-oPBn"},"source":["# Plot model architechture\n","tf.keras.utils.plot_model(model, to_file='graphics/architecture_ae.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GGhe1-BUITMu"},"source":["## Iterate training"]},{"cell_type":"code","metadata":{"id":"xXGQ4kbwIVw1"},"source":["import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","# Iterate training session\n","losses = []    \n","eval_x = []\n","eval_y = []\n","for epoch in range(num_epochs):\n","    print ('Epoch: ', epoch)\n","\n","    for data in train_set:\n","        losses.extend(np.array(train_step(data)).flatten())\n","        end_data = data\n","\n","    if epoch % 10 == 0:\n","        model.save_weights(ckpt_path.format(epoch=epoch),\n","                           save_format='h5',\n","                           )\n","        eval_x.append(len(losses))\n","        evls_train, _, imgs_train, msks_train = test_step(end_data)\n","        accum_valid_loss = []\n","        for x_valid in valid_set:\n","            evls_valid, valid_loss, imgs_valid, msks_valid = test_step(x_valid)\n","            valid_loss = np.array(valid_loss).flatten()\n","            accum_valid_loss.extend(valid_loss)\n","        valid_loss = np.mean(accum_valid_loss)\n","        eval_y.append(valid_loss)\n","        print('Checkpoint at epoch ', epoch)\n","        print('losses[-1]: ', losses[-1])\n","        print('\\n')\n","\n","        # Graphical Output\n","        for i in range(min(batch_size, 1)):\n","\n","            print('\\nTraining Results:')\n","            print ('np.max(evals_train[i, :, :, 0]): ',\n","                   np.max(evls_train[i, :, :, 0]),\n","                   )\n","            print ('np.min(evals_train[i, :, :, 0]): ',\n","                   np.min(evls_train[i, :, :, 0]),\n","                   )\n","            fig, ax = plt.subplots(1, 3, constrained_layout=True)\n","            ax[0].imshow(imgs_train[i, :, :, 0])\n","            ax[0].set_title('Input')\n","            ax[1].imshow(msks_train[i, :, :, 0])\n","            ax[1].set_title('Mask')\n","            ax[2].imshow(evls_train[i, :, :, 0])\n","            ax[2].set_title('Prediction')\n","            #fig.suptitle('Training Set Results', fontsize=16)\n","            plt.show()\n","            fig.savefig(graphics_dir +\n","                        '/training_output_bnum{:02d}_epoch{:04d}'\n","                        .format(i, epoch)\n","                        )\n","\n","            print('\\nValidation Results:')\n","            print ('np.max(evls_valid[i, :, :, 0]): ',\n","                   np.max(evls_valid[i, :, :, 0]),\n","                   )\n","            print ('np.min(evls_valid[i, :, :, 0]): ',\n","                   np.min(evls_valid[i, :, :, 0]),\n","                   )\n","            fig, ax = plt.subplots(1, 3, constrained_layout=True)\n","            ax[0].imshow(imgs_valid[i, :, :, 0])\n","            ax[0].set_title('Input')\n","            ax[1].imshow(msks_valid[i, :, :, 0])\n","            ax[1].set_title('Mask')\n","            ax[2].imshow(evls_valid[i, :, :, 0])\n","            ax[2].set_title('Prediction')\n","            #fig.suptitle('Validation Results', fontsize=16)\n","            plt.show()\n","            fig.savefig(graphics_dir +\n","                        '/training_output_bnum{:02d}_epoch{:04d}'\n","                        .format(i, epoch)\n","                        )\n","    \n","fig, ax = plt.subplots(1, 1)\n","ax.plot(losses, color='g', label='Training loss')\n","ax.plot(eval_x, eval_y, color='r', label='Validation loss')\n","ax.legend()\n","plt.show()\n","fig.savefig(graphics_dir + '/loss_record')\n"],"execution_count":null,"outputs":[]}]}